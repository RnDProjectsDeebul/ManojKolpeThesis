%!TEX root = ../report.tex

\begin{document}
    \chapter{Conclusions}
	\label{chap:conclusion}
	
	In general settings, semantic segmentation of the video sequence data is done by performing segmentation on the keyframes or the entire frames without fusing the rich information from the previous frame. The overlapping data in the consecutive frames can be propagated and fused forward to improve the segmentation performance. This project studies the latent space encoding temporal fusion in the context of continuous sequence video data with the help of the Gaussian Process (GP) and Long Short-Term Memory (LSTM). Comparative evaluation of the baseline, GP, and LSTM is conducted, and the best-performing model is deployed on an android device. In order to conduct the experiment, Scannet and Vkitti data are considered. It is a continuous video sequence data with overlapping information in consecutive frames. The overlapping data is leveraged for temporal fusion with the help of GP and LSTM. The overlapping information is modeled with the help of camera pose information for the GP, and a convolution LSTM cell is introduced in the latent space encoding for temporal fusion from the previous frames. The impact of the training batch size on the model performance is also studied. The main objective of the project is to
	
	\begin{itemize}
		\item Literature review on the temporal fusion models
		\item Comparison of the state of the art temporal fusion architecture performance
		\item Implementation of the baseline encoder-decoder type Unet model
		\item Model the overlapping information with pose information and fuse the data in the latent space encoding with the Gaussian Process
		\item Temporal fusion in the latent space encoding with LSTM
		\item Comparative evaluation of the baseline, GP and LSTM model performance
		\item Implementation of best performing model on the android device
		
	\end{itemize} 
	
	Challenges encountered during the projects
	
	\begin{itemize}
		\item Finding the dataset containing the pose information
		\item How to fuse the information?
		\item Lightweight encoder-decoder architecture
	\end{itemize}
	
	The project objectives were implemented after thoroughly investigating the temporal fusion approach. The challenges are addressed technically. Temporal fusion in the context of video sequence data is challenging due to the problem's complexity. Suitable tools and standard approaches are followed to tackle the fusion of highly related consecutive frames information, thereby solving the fusion problem. Standard research approaches are followed in a technically sound manner, starting with a literature review to implementing the cross-transferred theorized approach from the depth estimation problem. A detailed introduction to the general temporal fusion approach, motivation, challenges and difficulties, use cases, and research questions are discussed in the introduction section \ref{chap:introduction}. There is a significant amount of work focused on the temporal fusion approach, which involves combining features and using different architectures for fusion. Best performing temporal fusion approaches are discussed in the state-of-the-art section \ref{chap:stateofart}. After a detailed analysis of the state-of-the-art temporal fusion approaches, an appropriate dataset meeting the requirements set by the experiments need to be collected. A sample of the collected dataset is described. The architecture of the baseline Unet model, temporal fusing Gaussian process, and Long Short Term Memory Unet model is discussed in the methodology section \ref{chap:methodology}. The training pipeline, evaluation pipeline, and hardware configuration are also discussed in this section. Multiple metrics are used to evaluate the performance of the baseline and temporally fused semantic segmentation models, such as Pixel accuracy, mean pixel accuracy, IoU, mIoU, and FwIoU. A hypothesis is initially developed before conducting the experiments. All the research questions starting with state-of-the-art temporal fusion architecture, comparison of model performance, cross-transfer of temporal fusion technique to semantic segmentation, Gaussian Process, and LSTM approaches, are discussed. The model performance results are tabulated and compared side by side to reject or accept the developed hypothesis. Finally, the best-performing models are described with different metrics in the evaluation and experimental result \ref{chap:evaluationandresult} section. The best-performing models are finally deployed in an android device using the Kotlin and Chaquopy framework. The implementation details are described in the android deployment \ref{chap:androiddeploy} section. The report is summarized in the conclusion section \ref{chap:conclusion}.       
	
    \section{Contributions}
	
	The contribution of the project are listed below
	
	\begin{itemize}
		\item Literature review on state of the art temporal fusion in semantic segmentation
		\item Detailed analysis of the video sequence data
		\item Implementation of the baseline encoder-decoder based Unet model
		\item Incorporation of Gaussian Process temporal fusion in latent space encoding of Unet model
		\item Incorporation of Long Short Term Memory temporal fusion in latent space encoding of Unet model
		\item Study of training batch size on the model performance
		\item Implementation of best performing model on a android device
	\end{itemize}
	
	
    \section{Limitation}

	The temporal fusion using the Gaussian Process involve solving of a matrix equation to propagate the overlapping information forward, and the process involve matrix inversion. As the matrix size increases the inversion becomes costly and takes long time to process, thereby increasing the processing power requirements. The temporal fusion works if there is overlapping information in the consecutive frames. Hence for a video sequence data the frames rate needs to be high so that the probability of overlapping information is quite high. The effect of temporal fusion is not immediately seen rather observed after few frames prediction. Gaussian Process model the temporal data with the help of covariance matrix. The covariance matrix depend on the distance matrix, which in turn depend on the pose information of the captured frames.Thereby the Gaussian Process works only if there is pose information. Extra sensor is needed to extract the pose data. However, the Long Short Term Memory (LSTM) works without the need of pose information, but need high computation in comparison with the Gaussian Process. The android and ios are in early stage of deploying the deep learning models with these low computational device. There are lot of modules needed to deploy the developed model. Hence, a third party software needs to be incorporated to tackle the setback. 

    \section{Future work}
    
	The transformers can be employed in the temporal fusion of the latent space encoding, thereby propagating the overlapping information forward. The kernel of the Gaussian Process can be changed, thereby experimenting with different kernel and tabulating the results is the future direction for the temporal fusion approach. The impact of temporal fusion on video sequence data containing non overlapping information can be studied in the future. Lighting condition has a affect on the model prediction and learning process. Noise can be injected into the video sequence data and uncertainty of model prediction can be studied.
    
\end{document}
