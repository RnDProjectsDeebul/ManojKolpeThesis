\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{35_mldl}
\citation{55_WinNT}
\citation{60_minaee2021image}
\citation{64_noh2015learning}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{xv}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Tables}{xvii}{chapter*.5}\protected@file@percent }
\citation{01_mandic2005data}
\citation{06_castanedo2013review}
\citation{02_lim2021temporal}
\citation{03_duzceker2021deepvideomvs}
\citation{04_li2021spatial}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Data fusion categories based on timestamp\relax }}{1}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:3D_reconstruction}{{1.1}{1}{Data fusion categories based on timestamp\relax }{figure.caption.6}{}}
\citation{005_hsiao2005temporal}
\citation{07_hsiao2005temporal}
\citation{07_hsiao2005temporal}
\citation{08_krause2003unsupervised}
\citation{09_lee2003line}
\citation{10_han2016seq}
\citation{11_kang2017t}
\citation{12_ning2017spatially}
\citation{13_lu2020retinatrack}
\citation{14_kopuklu2019you}
\citation{15_feichtenhofer2016convolutional}
\citation{16_wang2016temporal}
\citation{17_erccelik2021temp}
\citation{18_zhu2009spatial}
\citation{19_wu2003multi}
\citation{20_teutsch2012spatio}
\citation{21_forsyth2011computer}
\citation{22_dai2016instance}
\citation{23_fu1981survey}
\citation{24_ladys1994colour}
\citation{25_minaee2021image}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Temporal fusion}{2}{subsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Semantic segmentation}{3}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Challenges and Difficulties}{3}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Dataset}{3}{subsection.1.2.1}\protected@file@percent }
\citation{26_ronneberger2015u}
\citation{27_lin2017refinenet}
\citation{28_jegou2017one}
\citation{29_iandola2014densenet}
\citation{30_yang2018denseaspp}
\citation{25_minaee2021image}
\citation{31_chen2014semantic}
\citation{32_zhao2018icnet}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Fusion architecture}{4}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Computation cost}{4}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Real time inference for various application areas}{4}{subsection.1.2.4}\protected@file@percent }
\citation{33_deng2020lightweight}
\citation{34_hsieh2010real}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Use cases}{5}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Autonomous driving and Robotics}{5}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Weed mapping using Unmanned Aerial Vehicle (UAV)}{5}{subsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Real-Time Hand Gesture Recognition}{5}{subsection.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Problem Statement and Contribution}{6}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Research question}{6}{subsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Contribution}{6}{subsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Report outline}{6}{section.1.5}\protected@file@percent }
\citation{35_mldl}
\citation{35_mldl}
\citation{36_lecun2015deep}
\citation{36_lecun2015deep}
\citation{36_lecun2015deep}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}State of the Art}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:stateofart}{{2}{7}{State of the Art}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Deep Learning}{7}{section.2.1}\protected@file@percent }
\newlabel{sec:deeplearn}{{2.1}{7}{Deep Learning}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Deep learning in the artificial intelligence domain. Courtesy of \cite  {35_mldl}\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:DLAI}{{2.1}{7}{Deep learning in the artificial intelligence domain. Courtesy of \cite {35_mldl}\relax }{figure.caption.7}{}}
\citation{37_farabet2012learning}
\citation{38_hinton2012deep}
\citation{39_patel2020machine}
\citation{40_ciodaro2012online}
\citation{41_zhang2021deep}
\citation{42_hirschberg2015advances}
\citation{46_o2019deep}
\citation{44_mohanty2016using}
\citation{45_han2021ecological}
\citation{43_srivastava2021comparative}
\citation{47_minaee2021image}
\citation{48_jensen1999temporal}
\citation{49_atluri2018spatio}
\citation{50_lim2021temporal}
\citation{51_meng2021adafuse}
\citation{52_hou2019multi}
\citation{53_duzceker2021deepvideomvs}
\citation{54_zhang2021multiple}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Temporal Fusion}{8}{section.2.2}\protected@file@percent }
\newlabel{sec:tempfuse}{{2.2}{8}{Temporal Fusion}{section.2.2}{}}
\citation{55_WinNT}
\citation{55_WinNT}
\citation{56_otsu1979threshold}
\citation{57_otsu1979threshold}
\citation{58_boykov2001fast}
\citation{59_starck2005image}
\citation{60_minaee2021image}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Semantic Segmentation}{9}{section.2.3}\protected@file@percent }
\newlabel{sec:semseg}{{2.3}{9}{Semantic Segmentation}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Classical Semantic Segmentation}{9}{subsection.2.3.1}\protected@file@percent }
\citation{61_chen2017rethinking}
\citation{62_badrinarayanan2017segnet}
\citation{60_minaee2021image}
\citation{63_goodfellow2014generative}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Semantic and Instance segmentation example. Courtesy of \cite  {55_WinNT}\relax }}{10}{figure.caption.8}\protected@file@percent }
\newlabel{fig:SS}{{2.2}{10}{Semantic and Instance segmentation example. Courtesy of \cite {55_WinNT}\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Deep Learning based Semantic Segmentation}{10}{subsection.2.3.2}\protected@file@percent }
\citation{60_minaee2021image}
\citation{60_minaee2021image}
\citation{64_noh2015learning}
\citation{64_noh2015learning}
\citation{64_noh2015learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Simple encoder-decoder architecture. Courtesy of \cite  {60_minaee2021image}\relax }}{11}{figure.caption.9}\protected@file@percent }
\newlabel{fig:en_de}{{2.3}{11}{Simple encoder-decoder architecture. Courtesy of \cite {60_minaee2021image}\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Simple encoder-decoder architecture. Courtesy of \cite  {64_noh2015learning}\relax }}{11}{figure.caption.10}\protected@file@percent }
\newlabel{fig:general_seg}{{2.4}{11}{Simple encoder-decoder architecture. Courtesy of \cite {64_noh2015learning}\relax }{figure.caption.10}{}}
\citation{art1}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Temporal Fusion in Semantic Segmentation}{12}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Limitations of previous work}{12}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{13}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methodology}{{3}{13}{Methodology}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset}{13}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}ScanNet}{13}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Virtual KITTI 2}{13}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}VIODE}{13}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Data Collection and Preprocessing}{13}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Experimental Design}{13}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}U-Net Vanilla model}{13}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}U-Net with Temporal Fusion}{13}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}W-Net Vanilla model}{13}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}W-Net with Temporal Fusion}{13}{subsection.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Training and Evaluation Pipeline}{13}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Training Procedure}{13}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Hardware Configuration}{13}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Evaluation and Experimental Result}{15}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:evaluationandresult}{{4}{15}{Evaluation and Experimental Result}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Evaluation Metric}{16}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Pixel Accuracy}{16}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Precision}{16}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Recall}{16}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}ROC and AUC}{16}{subsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}IOU}{16}{subsection.4.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}RQ1: What are the works on state-of-the-art temporal fusion?}{16}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Experiment1.1: U-Net and W-Net model with single sequence data}{16}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Experiment1.2: U-Net and W-Net model with two sequence data}{16}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Experiment1.3: U-Net and W-Net model with three sequence data}{16}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Experiment1.4: U-Net and W-Net model with four sequence data}{16}{subsection.4.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Experiment1.5: U-Net and W-Net model with all sequence data}{16}{subsection.4.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}RQ2: How are the results from RQ1 compared with each other to perform temporal fusion?}{16}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Experiment1.1: U-Net and W-Net model with single sequence data}{16}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Experiment1.2: U-Net and W-Net model with two sequence data}{16}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Experiment1.3: U-Net and W-Net model with three sequence data}{16}{subsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Experiment1.4: U-Net and W-Net model with four sequence data}{16}{subsection.4.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Experiment1.5: U-Net and W-Net model with all sequence data}{16}{subsection.4.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}RQ3: How to cross-transfer the temporal fusion technique to semantic segmentation?}{16}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Experiment1.1: U-Net vanilla model}{16}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Experiment1.2: U-Net temporally fused gp model}{16}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Experiment1.3: U-Net temporally fused lstm model}{16}{subsection.4.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Android Deployment}{17}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:androiddeploy}{{5}{17}{Android Deployment}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Framework}{17}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Pipeline}{17}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Deployment and Results}{17}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions}{19}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{6}{19}{Conclusions}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Contributions}{19}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Lessons learned}{19}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Future work}{19}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Appendix \numberline {A}Design Details}{21}{appendix.a.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Appendix \numberline {B}Parameters}{23}{appendix.a.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{unsrt}
\bibdata{references}
\bibcite{35_mldl}{1}
\bibcite{55_WinNT}{2}
\bibcite{60_minaee2021image}{3}
\bibcite{64_noh2015learning}{4}
\bibcite{01_mandic2005data}{5}
\bibcite{06_castanedo2013review}{6}
\bibcite{02_lim2021temporal}{7}
\bibcite{03_duzceker2021deepvideomvs}{8}
\bibcite{04_li2021spatial}{9}
\bibcite{005_hsiao2005temporal}{10}
\bibcite{07_hsiao2005temporal}{11}
\bibcite{08_krause2003unsupervised}{12}
\@writefile{toc}{\contentsline {chapter}{References}{25}{appendix*.11}\protected@file@percent }
\bibcite{09_lee2003line}{13}
\bibcite{10_han2016seq}{14}
\bibcite{11_kang2017t}{15}
\bibcite{12_ning2017spatially}{16}
\bibcite{13_lu2020retinatrack}{17}
\bibcite{14_kopuklu2019you}{18}
\bibcite{15_feichtenhofer2016convolutional}{19}
\bibcite{16_wang2016temporal}{20}
\bibcite{17_erccelik2021temp}{21}
\bibcite{18_zhu2009spatial}{22}
\bibcite{19_wu2003multi}{23}
\bibcite{20_teutsch2012spatio}{24}
\bibcite{21_forsyth2011computer}{25}
\bibcite{22_dai2016instance}{26}
\bibcite{23_fu1981survey}{27}
\bibcite{24_ladys1994colour}{28}
\bibcite{25_minaee2021image}{29}
\bibcite{26_ronneberger2015u}{30}
\bibcite{27_lin2017refinenet}{31}
\bibcite{28_jegou2017one}{32}
\bibcite{29_iandola2014densenet}{33}
\bibcite{30_yang2018denseaspp}{34}
\bibcite{31_chen2014semantic}{35}
\bibcite{32_zhao2018icnet}{36}
\bibcite{33_deng2020lightweight}{37}
\bibcite{34_hsieh2010real}{38}
\bibcite{36_lecun2015deep}{39}
\bibcite{37_farabet2012learning}{40}
\bibcite{38_hinton2012deep}{41}
\bibcite{39_patel2020machine}{42}
\bibcite{40_ciodaro2012online}{43}
\bibcite{41_zhang2021deep}{44}
\bibcite{42_hirschberg2015advances}{45}
\bibcite{46_o2019deep}{46}
\bibcite{44_mohanty2016using}{47}
\bibcite{45_han2021ecological}{48}
\bibcite{43_srivastava2021comparative}{49}
\bibcite{47_minaee2021image}{50}
\bibcite{48_jensen1999temporal}{51}
\bibcite{49_atluri2018spatio}{52}
\bibcite{50_lim2021temporal}{53}
\bibcite{51_meng2021adafuse}{54}
\bibcite{52_hou2019multi}{55}
\bibcite{53_duzceker2021deepvideomvs}{56}
\bibcite{54_zhang2021multiple}{57}
\bibcite{56_otsu1979threshold}{58}
\bibcite{57_otsu1979threshold}{59}
\bibcite{58_boykov2001fast}{60}
\bibcite{59_starck2005image}{61}
\bibcite{61_chen2017rethinking}{62}
\bibcite{62_badrinarayanan2017segnet}{63}
\bibcite{63_goodfellow2014generative}{64}
\bibcite{05_hsiao2005temporal}{65}
\citation{*}
