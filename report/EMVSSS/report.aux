\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{35_mldl}
\citation{52_hou2019multi}
\citation{55_WinNT}
\citation{60_minaee2021image}
\citation{64_noh2015learning}
\citation{62_badrinarayanan2017segnet}
\citation{70_ronneberger2015u}
\citation{78_hu2020temporally}
\citation{82_iou}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{xv}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Tables}{xvii}{chapter*.5}\protected@file@percent }
\citation{01_mandic2005data}
\citation{06_castanedo2013review}
\citation{02_lim2021temporal}
\citation{03_duzceker2021deepvideomvs}
\citation{04_li2021spatial}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Data fusion categories based on timestamp\relax }}{1}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:3D_reconstruction}{{1.1}{1}{Data fusion categories based on timestamp\relax }{figure.caption.6}{}}
\citation{005_hsiao2005temporal}
\citation{07_hsiao2005temporal}
\citation{07_hsiao2005temporal}
\citation{08_krause2003unsupervised}
\citation{09_lee2003line}
\citation{10_han2016seq}
\citation{11_kang2017t}
\citation{12_ning2017spatially}
\citation{13_lu2020retinatrack}
\citation{14_kopuklu2019you}
\citation{15_feichtenhofer2016convolutional}
\citation{16_wang2016temporal}
\citation{17_erccelik2021temp}
\citation{18_zhu2009spatial}
\citation{19_wu2003multi}
\citation{20_teutsch2012spatio}
\citation{21_forsyth2011computer}
\citation{22_dai2016instance}
\citation{23_fu1981survey}
\citation{24_ladys1994colour}
\citation{25_minaee2021image}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Temporal fusion}{2}{subsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Semantic segmentation}{3}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Challenges and Difficulties}{3}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Dataset}{3}{subsection.1.2.1}\protected@file@percent }
\citation{26_ronneberger2015u}
\citation{27_lin2017refinenet}
\citation{28_jegou2017one}
\citation{29_iandola2014densenet}
\citation{30_yang2018denseaspp}
\citation{25_minaee2021image}
\citation{31_chen2014semantic}
\citation{32_zhao2018icnet}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Fusion architecture}{4}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Computation cost}{4}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Real time inference for various application areas}{4}{subsection.1.2.4}\protected@file@percent }
\citation{33_deng2020lightweight}
\citation{34_hsieh2010real}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Use cases}{5}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Autonomous driving and Robotics}{5}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Weed mapping using Unmanned Aerial Vehicle (UAV)}{5}{subsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Real-Time Hand Gesture Recognition}{5}{subsection.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Problem Statement and Contribution}{6}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Research question}{6}{subsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Contribution}{6}{subsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Report outline}{6}{section.1.5}\protected@file@percent }
\citation{35_mldl}
\citation{35_mldl}
\citation{36_lecun2015deep}
\citation{36_lecun2015deep}
\citation{36_lecun2015deep}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}State of the Art}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:stateofart}{{2}{7}{State of the Art}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Deep Learning}{7}{section.2.1}\protected@file@percent }
\newlabel{sec:deeplearn}{{2.1}{7}{Deep Learning}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Deep learning in the artificial intelligence domain. Courtesy of \cite  {35_mldl}\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:DLAI}{{2.1}{7}{Deep learning in the artificial intelligence domain. Courtesy of \cite {35_mldl}\relax }{figure.caption.7}{}}
\citation{37_farabet2012learning}
\citation{38_hinton2012deep}
\citation{39_patel2020machine}
\citation{40_ciodaro2012online}
\citation{41_zhang2021deep}
\citation{42_hirschberg2015advances}
\citation{46_o2019deep}
\citation{44_mohanty2016using}
\citation{45_han2021ecological}
\citation{43_srivastava2021comparative}
\citation{47_minaee2021image}
\citation{48_jensen1999temporal}
\citation{49_atluri2018spatio}
\citation{50_lim2021temporal}
\citation{51_meng2021adafuse}
\citation{52_hou2019multi}
\citation{53_duzceker2021deepvideomvs}
\citation{54_zhang2021multiple}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Temporal Fusion}{8}{section.2.2}\protected@file@percent }
\newlabel{sec:tempfuse}{{2.2}{8}{Temporal Fusion}{section.2.2}{}}
\citation{52_hou2019multi}
\citation{52_hou2019multi}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Mulit view stereo architecture for depth estimation. Courtesy of \cite  {52_hou2019multi}\relax }}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:mvs}{{2.2}{9}{Mulit view stereo architecture for depth estimation. Courtesy of \cite {52_hou2019multi}\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Semantic Segmentation}{9}{section.2.3}\protected@file@percent }
\newlabel{sec:semseg}{{2.3}{9}{Semantic Segmentation}{section.2.3}{}}
\citation{55_WinNT}
\citation{55_WinNT}
\citation{56_otsu1979threshold}
\citation{57_otsu1979threshold}
\citation{58_boykov2001fast}
\citation{59_starck2005image}
\citation{60_minaee2021image}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Semantic and Instance segmentation example. Courtesy of \cite  {55_WinNT}\relax }}{10}{figure.caption.9}\protected@file@percent }
\newlabel{fig:SS}{{2.3}{10}{Semantic and Instance segmentation example. Courtesy of \cite {55_WinNT}\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Classical Semantic Segmentation}{10}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Deep Learning based Semantic Segmentation}{10}{subsection.2.3.2}\protected@file@percent }
\citation{61_chen2017rethinking}
\citation{62_badrinarayanan2017segnet}
\citation{60_minaee2021image}
\citation{63_goodfellow2014generative}
\citation{60_minaee2021image}
\citation{60_minaee2021image}
\citation{64_noh2015learning}
\citation{64_noh2015learning}
\citation{64_noh2015learning}
\citation{62_badrinarayanan2017segnet}
\citation{62_badrinarayanan2017segnet}
\citation{62_badrinarayanan2017segnet}
\citation{65_kendall2015bayesian}
\citation{66_sun2019high}
\citation{67_fu2019stacked}
\citation{68_hu2018learning}
\citation{69_xia2017w}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Simple encoder-decoder architecture. Courtesy of \cite  {60_minaee2021image}\relax }}{11}{figure.caption.10}\protected@file@percent }
\newlabel{fig:en_de}{{2.4}{11}{Simple encoder-decoder architecture. Courtesy of \cite {60_minaee2021image}\relax }{figure.caption.10}{}}
\citation{70_ronneberger2015u}
\citation{71_milletari2016v}
\citation{70_ronneberger2015u}
\citation{70_ronneberger2015u}
\citation{70_ronneberger2015u}
\citation{70_ronneberger2015u}
\citation{60_minaee2021image}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Simple encoder-decoder architecture. Courtesy of \cite  {64_noh2015learning}\relax }}{12}{figure.caption.11}\protected@file@percent }
\newlabel{fig:general_seg}{{2.5}{12}{Simple encoder-decoder architecture. Courtesy of \cite {64_noh2015learning}\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces SegNet architecture. Courtesy of \cite  {62_badrinarayanan2017segnet}\relax }}{12}{figure.caption.12}\protected@file@percent }
\newlabel{fig:segnet}{{2.6}{12}{SegNet architecture. Courtesy of \cite {62_badrinarayanan2017segnet}\relax }{figure.caption.12}{}}
\citation{72_jin2017video}
\citation{73_gadde2017semantic}
\citation{74_jin2017video}
\citation{75_nilsson2018semantic}
\citation{76_jain2019accel}
\citation{77_mahasseni2017budget}
\citation{78_hu2020temporally}
\citation{78_hu2020temporally}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Unet architecture. Courtesy of \cite  {70_ronneberger2015u}\relax }}{13}{figure.caption.13}\protected@file@percent }
\newlabel{fig:unet}{{2.7}{13}{Unet architecture. Courtesy of \cite {70_ronneberger2015u}\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Temporal Fusion in Semantic Segmentation}{13}{section.2.4}\protected@file@percent }
\citation{78_hu2020temporally}
\citation{78_hu2020temporally}
\citation{52_hou2019multi}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces TDNet. Courtesy of \cite  {78_hu2020temporally}\relax }}{14}{figure.caption.14}\protected@file@percent }
\newlabel{fig:TDNet}{{2.8}{14}{TDNet. Courtesy of \cite {78_hu2020temporally}\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Limitations of Previous Work}{14}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methodology}{{3}{15}{Methodology}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset}{15}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}ScanNet}{15}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Virtual KITTI 2}{15}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}VIODE}{15}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Data Collection and Preprocessing}{15}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Experimental Design}{15}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}U-Net Vanilla model}{15}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}U-Net with Temporal Fusion}{15}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}W-Net Vanilla model}{15}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}W-Net with Temporal Fusion}{15}{subsection.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Training and Evaluation Pipeline}{15}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Training Procedure}{15}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Hardware Configuration}{15}{section.3.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Classes and ids of the Scannet dataset\relax }}{16}{table.caption.15}\protected@file@percent }
\newlabel{table:Classes in scannet_1}{{3.1}{16}{Classes and ids of the Scannet dataset\relax }{table.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Classes and ids of the Scannet dataset\relax }}{17}{table.caption.16}\protected@file@percent }
\newlabel{table:Classes in scannet_2}{{3.2}{17}{Classes and ids of the Scannet dataset\relax }{table.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Classes and ids of the Scannet dataset\relax }}{18}{table.caption.17}\protected@file@percent }
\newlabel{table:Classes in scannet_3}{{3.3}{18}{Classes and ids of the Scannet dataset\relax }{table.caption.17}{}}
\citation{79_dai2017scannet}
\citation{80_cabon2020vkitti2}
\citation{81_minodaRAL2021}
\citation{84_ulku2022survey}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Evaluation and Experimental Result}{19}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:evaluationandresult}{{4}{19}{Evaluation and Experimental Result}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Evaluation Metric}{19}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Pixel Accuracy}{19}{subsection.4.1.1}\protected@file@percent }
\citation{83_iou}
\citation{82_iou}
\citation{82_iou}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}IoU}{20}{subsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces IoU. Courtesy of \cite  {82_iou}\relax }}{20}{figure.caption.18}\protected@file@percent }
\newlabel{fig:IoU}{{4.1}{20}{IoU. Courtesy of \cite {82_iou}\relax }{figure.caption.18}{}}
\citation{84_ulku2022survey}
\citation{84_ulku2022survey}
\citation{85_kag_challenge}
\citation{79_dai2017scannet}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}RQ1: What are the works on state-of-the-art temporal fusion?}{22}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Experiment1.1: U-Net and W-Net model with single sequence data}{22}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Experiment1.2: U-Net and W-Net model with two sequence data}{22}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Experiment1.3: U-Net and W-Net model with three sequence data}{22}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Experiment1.4: U-Net and W-Net model with four sequence data}{22}{subsection.4.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Experiment1.5: U-Net and W-Net model with all sequence data}{22}{subsection.4.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}RQ2: How are the results from RQ1 compared with each other to perform temporal fusion?}{22}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Experiment1.1: U-Net and W-Net model with single sequence data}{22}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Experiment1.2: U-Net and W-Net model with two sequence data}{22}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Experiment1.3: U-Net and W-Net model with three sequence data}{22}{subsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Experiment1.4: U-Net and W-Net model with four sequence data}{22}{subsection.4.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Experiment1.5: U-Net and W-Net model with all sequence data}{22}{subsection.4.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}RQ3: How to cross-transfer the temporal fusion technique to semantic segmentation?}{22}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Experiment1.1: U-Net vanilla model}{22}{subsection.4.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Per class pixel distribution of the ground truth pixel class label\relax }}{24}{figure.caption.19}\protected@file@percent }
\newlabel{fig:y_gt_vanilla}{{4.2}{24}{Per class pixel distribution of the ground truth pixel class label\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Experiment1.2: U-Net temporally fused gp model}{24}{subsection.4.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Per class pixel distribution of the predicted pixel class label\relax }}{25}{figure.caption.20}\protected@file@percent }
\newlabel{fig:y_predi_vanilla}{{4.3}{25}{Per class pixel distribution of the predicted pixel class label\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Experiment1.3: U-Net temporally fused lstm model}{25}{subsection.4.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Ordered set of images\relax }}{26}{figure.caption.21}\protected@file@percent }
\newlabel{fig:ordered set of images}{{4.4}{26}{Ordered set of images\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Distance matrix depicted as heatmap\relax }}{27}{figure.caption.22}\protected@file@percent }
\newlabel{fig:ordered set D}{{4.5}{27}{Distance matrix depicted as heatmap\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Kernel matrix depicted as heatmap\relax }}{28}{figure.caption.23}\protected@file@percent }
\newlabel{fig:ordered set of K}{{4.6}{28}{Kernel matrix depicted as heatmap\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Ordered set of images\relax }}{29}{figure.caption.24}\protected@file@percent }
\newlabel{fig:unordered set of images}{{4.7}{29}{Ordered set of images\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Distance matrix depicted as heatmap\relax }}{30}{figure.caption.25}\protected@file@percent }
\newlabel{fig:unordered set K}{{4.8}{30}{Distance matrix depicted as heatmap\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Kernel matrix depicted as heatmap\relax }}{31}{figure.caption.26}\protected@file@percent }
\newlabel{fig:unordered set of K}{{4.9}{31}{Kernel matrix depicted as heatmap\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Per class pixel distribution of the ground truth pixel class label for gp model\relax }}{32}{figure.caption.27}\protected@file@percent }
\newlabel{fig:y_gt_gp}{{4.10}{32}{Per class pixel distribution of the ground truth pixel class label for gp model\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Per class pixel distribution of the predicted pixel class label for gp model\relax }}{32}{figure.caption.28}\protected@file@percent }
\newlabel{fig:y_predi_gp}{{4.11}{32}{Per class pixel distribution of the predicted pixel class label for gp model\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Per class pixel distribution of the ground truth pixel class label for lstm model\relax }}{33}{figure.caption.29}\protected@file@percent }
\newlabel{fig:y_gt_lstm}{{4.12}{33}{Per class pixel distribution of the ground truth pixel class label for lstm model\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Per class pixel distribution of the predicted pixel class label for lstm model\relax }}{34}{figure.caption.30}\protected@file@percent }
\newlabel{fig:y_predi_lstm}{{4.13}{34}{Per class pixel distribution of the predicted pixel class label for lstm model\relax }{figure.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Performance of Vanilla model with respect to different metric and two classes\relax }}{34}{table.caption.32}\protected@file@percent }
\newlabel{table:Vanilla_conti_seq}{{4.1}{34}{Performance of Vanilla model with respect to different metric and two classes\relax }{table.caption.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Performance of GP model with respect to different metric and two classes\relax }}{34}{table.caption.34}\protected@file@percent }
\newlabel{table:GP_conti_seq}{{4.2}{34}{Performance of GP model with respect to different metric and two classes\relax }{table.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Plotting of raw input image, ground truth and vanilla model predicted output on a continuous sequence data\relax }}{35}{figure.caption.31}\protected@file@percent }
\newlabel{fig:output_vanilla}{{4.14}{35}{Plotting of raw input image, ground truth and vanilla model predicted output on a continuous sequence data\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Plotting of raw input image, ground truth and GP model predicted output on a continuous sequence two class data \relax }}{36}{figure.caption.33}\protected@file@percent }
\newlabel{fig:output_gp}{{4.15}{36}{Plotting of raw input image, ground truth and GP model predicted output on a continuous sequence two class data \relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces Plotting of raw input image, ground truth and lstm model predicted output on a continuous sequence two class data\relax }}{37}{figure.caption.35}\protected@file@percent }
\newlabel{fig:output_lstm}{{4.16}{37}{Plotting of raw input image, ground truth and lstm model predicted output on a continuous sequence two class data\relax }{figure.caption.35}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Performance of LSTM model with respect to different metric and two classes\relax }}{38}{table.caption.36}\protected@file@percent }
\newlabel{table:LSTM_conti_seq}{{4.3}{38}{Performance of LSTM model with respect to different metric and two classes\relax }{table.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Temporal fusion on a continuous sequence data}{38}{subsection.4.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}RQ3.1: Which fusion method is good for the scannet data?}{38}{subsection.4.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}RQ3.2: Which fusion method is good for the virtual kitti data?}{38}{subsection.4.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.7}RQ3.3: Which fusion method is good for the VIODE data?}{38}{subsection.4.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Android Deployment}{39}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:androiddeploy}{{5}{39}{Android Deployment}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Framework}{39}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Pipeline}{39}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Deployment and Results}{39}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions}{41}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{6}{41}{Conclusions}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Contributions}{41}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Lessons learned}{41}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Future work}{41}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Appendix \numberline {A}Design Details}{43}{appendix.a.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Appendix \numberline {B}Parameters}{45}{appendix.a.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{unsrt}
\bibdata{references}
\bibcite{35_mldl}{1}
\bibcite{52_hou2019multi}{2}
\bibcite{55_WinNT}{3}
\bibcite{60_minaee2021image}{4}
\bibcite{64_noh2015learning}{5}
\bibcite{62_badrinarayanan2017segnet}{6}
\bibcite{70_ronneberger2015u}{7}
\bibcite{78_hu2020temporally}{8}
\bibcite{82_iou}{9}
\bibcite{01_mandic2005data}{10}
\bibcite{06_castanedo2013review}{11}
\bibcite{02_lim2021temporal}{12}
\bibcite{03_duzceker2021deepvideomvs}{13}
\@writefile{toc}{\contentsline {chapter}{References}{47}{appendix*.37}\protected@file@percent }
\bibcite{04_li2021spatial}{14}
\bibcite{005_hsiao2005temporal}{15}
\bibcite{07_hsiao2005temporal}{16}
\bibcite{08_krause2003unsupervised}{17}
\bibcite{09_lee2003line}{18}
\bibcite{10_han2016seq}{19}
\bibcite{11_kang2017t}{20}
\bibcite{12_ning2017spatially}{21}
\bibcite{13_lu2020retinatrack}{22}
\bibcite{14_kopuklu2019you}{23}
\bibcite{15_feichtenhofer2016convolutional}{24}
\bibcite{16_wang2016temporal}{25}
\bibcite{17_erccelik2021temp}{26}
\bibcite{18_zhu2009spatial}{27}
\bibcite{19_wu2003multi}{28}
\bibcite{20_teutsch2012spatio}{29}
\bibcite{21_forsyth2011computer}{30}
\bibcite{22_dai2016instance}{31}
\bibcite{23_fu1981survey}{32}
\bibcite{24_ladys1994colour}{33}
\bibcite{25_minaee2021image}{34}
\bibcite{26_ronneberger2015u}{35}
\bibcite{27_lin2017refinenet}{36}
\bibcite{28_jegou2017one}{37}
\bibcite{29_iandola2014densenet}{38}
\bibcite{30_yang2018denseaspp}{39}
\bibcite{31_chen2014semantic}{40}
\bibcite{32_zhao2018icnet}{41}
\bibcite{33_deng2020lightweight}{42}
\bibcite{34_hsieh2010real}{43}
\bibcite{36_lecun2015deep}{44}
\bibcite{37_farabet2012learning}{45}
\bibcite{38_hinton2012deep}{46}
\bibcite{39_patel2020machine}{47}
\bibcite{40_ciodaro2012online}{48}
\bibcite{41_zhang2021deep}{49}
\bibcite{42_hirschberg2015advances}{50}
\bibcite{46_o2019deep}{51}
\bibcite{44_mohanty2016using}{52}
\bibcite{45_han2021ecological}{53}
\bibcite{43_srivastava2021comparative}{54}
\bibcite{47_minaee2021image}{55}
\bibcite{48_jensen1999temporal}{56}
\bibcite{49_atluri2018spatio}{57}
\bibcite{50_lim2021temporal}{58}
\bibcite{51_meng2021adafuse}{59}
\bibcite{53_duzceker2021deepvideomvs}{60}
\bibcite{54_zhang2021multiple}{61}
\bibcite{56_otsu1979threshold}{62}
\bibcite{57_otsu1979threshold}{63}
\bibcite{58_boykov2001fast}{64}
\bibcite{59_starck2005image}{65}
\bibcite{61_chen2017rethinking}{66}
\bibcite{63_goodfellow2014generative}{67}
\bibcite{65_kendall2015bayesian}{68}
\bibcite{66_sun2019high}{69}
\bibcite{67_fu2019stacked}{70}
\bibcite{68_hu2018learning}{71}
\bibcite{69_xia2017w}{72}
\bibcite{71_milletari2016v}{73}
\bibcite{72_jin2017video}{74}
\bibcite{73_gadde2017semantic}{75}
\bibcite{74_jin2017video}{76}
\bibcite{75_nilsson2018semantic}{77}
\bibcite{76_jain2019accel}{78}
\bibcite{77_mahasseni2017budget}{79}
\bibcite{79_dai2017scannet}{80}
\bibcite{80_cabon2020vkitti2}{81}
\bibcite{81_minodaRAL2021}{82}
\bibcite{84_ulku2022survey}{83}
\bibcite{83_iou}{84}
\bibcite{85_kag_challenge}{85}
\bibcite{05_hsiao2005temporal}{86}
\citation{*}
