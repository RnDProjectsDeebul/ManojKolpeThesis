\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Data fusion categories based on timestamp\relax }}{1}{figure.caption.6}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Deep learning in the artificial intelligence domain. Courtesy of \cite {35_mldl}\relax }}{7}{figure.caption.7}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Mulit view stereo architecture for depth estimation. Courtesy of \cite {52_hou2019multi}\relax }}{9}{figure.caption.8}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Semantic and Instance segmentation example. Courtesy of \cite {55_WinNT}\relax }}{10}{figure.caption.9}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Simple encoder-decoder architecture. Courtesy of \cite {60_minaee2021image}\relax }}{11}{figure.caption.10}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Simple encoder-decoder architecture. Courtesy of \cite {64_noh2015learning}\relax }}{12}{figure.caption.11}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces SegNet architecture. Courtesy of \cite {62_badrinarayanan2017segnet}\relax }}{12}{figure.caption.12}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Unet architecture. Courtesy of \cite {70_ronneberger2015u}\relax }}{13}{figure.caption.13}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces TDNet. Courtesy of \cite {78_hu2020temporally}\relax }}{14}{figure.caption.14}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces IoU. Courtesy of \cite {82_iou}\relax }}{20}{figure.caption.18}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Per class pixel distribution of the entire scannet dataset\relax }}{23}{figure.caption.19}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Pixel distribution for the scannet data containing all the classes\relax }}{23}{figure.caption.20}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Pixel distribution for the scannet data for two classes\relax }}{24}{figure.caption.21}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Pixel distribution for the scannet data for three classes\relax }}{24}{figure.caption.22}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Ordered and Unordered set of images\relax }}{25}{figure.caption.23}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Distance matrix and Kernel matrix for ordered set of images\relax }}{26}{figure.caption.24}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Distance matrix and Kernel matrix for unordered set of images\relax }}{26}{figure.caption.25}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Pixel distribution for the ground truth and predicted scannet data for vanilla unet model\relax }}{27}{figure.caption.27}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Per class pixel distribution of the predicted pixel class label for gp model\relax }}{28}{figure.caption.29}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Per class pixel distribution of the predicted pixel class label for lstm model\relax }}{29}{figure.caption.31}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces Comparison of VANILLA, GP and LSTM model performance based on metric\relax }}{30}{figure.caption.32}%
\contentsline {figure}{\numberline {4.13}{\ignorespaces Comparison of VANILLA, GP and LSTM model performance\relax }}{31}{figure.caption.33}%
\contentsline {figure}{\numberline {4.14}{\ignorespaces Plotting of raw input image, ground truth and predicted output for vanilla, gp and lstm model\relax }}{32}{figure.caption.34}%
\contentsline {figure}{\numberline {4.15}{\ignorespaces Comparison of VANILLA, GP and LSTM model performance based on metric for scannet two classes\relax }}{33}{figure.caption.36}%
\contentsline {figure}{\numberline {4.16}{\ignorespaces Plotting of raw input image, ground truth and predicted output for vanilla, gp and lstm model\relax }}{33}{figure.caption.37}%
\contentsline {figure}{\numberline {4.17}{\ignorespaces Plotting of raw input image, ground truth and predicted output for vanilla, gp and lstm model\relax }}{34}{figure.caption.39}%
\contentsline {figure}{\numberline {4.18}{\ignorespaces Plotting of raw input image, ground truth and predicted output for vanilla, gp and lstm\relax }}{35}{figure.caption.40}%
\contentsline {figure}{\numberline {4.19}{\ignorespaces Plotting of raw input image, ground truth and predicted output for vanilla, gp and lstm\relax }}{36}{figure.caption.42}%
\contentsline {figure}{\numberline {4.20}{\ignorespaces Plotting of raw input image, ground truth and predicted output for vanilla, gp and lstm\relax }}{37}{figure.caption.43}%
\contentsline {figure}{\numberline {4.21}{\ignorespaces Plotting of raw input image, ground truth and predicted output for vanilla, gp and lstm\relax }}{38}{figure.caption.44}%
\contentsline {figure}{\numberline {4.22}{\ignorespaces Plotting of raw input image, ground truth and predicted output for vanilla, gp and lstm\relax }}{39}{figure.caption.46}%
\contentsline {figure}{\numberline {4.23}{\ignorespaces Plotting of raw input image, ground truth and predicted output for vanilla, gp and lstm\relax }}{39}{figure.caption.47}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
